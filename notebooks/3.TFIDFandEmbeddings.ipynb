{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LorenzoBellomo/InformationRetrieval/blob/main/notebooks/2_TFIDFandEmbeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmm4PBxppLmM"
      },
      "source": [
        "# Text processing with vectors\n",
        "In this lecture we focus on techinques that allow to model the text as vectors of floating point numbers. This allows us to easily process and compute similarities between words, sentences, and documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfJQqUBQroYR",
        "outputId": "1eb295a3-c4e9-45ed-a09b-a0a7d1fd386d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn\n",
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64D0vyV7se0x",
        "outputId": "8b91e427-ad73-41ce-cc70-d3adec41a5ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ylr9BKyosL9e",
        "outputId": "a550e2d5-f14f-44f5-9e22-bdbf14cf93db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-03-01 11:09:14--  https://raw.githubusercontent.com/giusprencunipi/IR-Master/main/data/5articles.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12566 (12K) [text/plain]\n",
            "Saving to: ‘5articles.json’\n",
            "\n",
            "\r5articles.json        0%[                    ]       0  --.-KB/s               \r5articles.json      100%[===================>]  12.27K  --.-KB/s    in 0s      \n",
            "\n",
            "2026-03-01 11:09:15 (67.6 MB/s) - ‘5articles.json’ saved [12566/12566]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/giusprencunipi/IR-Master/main/data/5articles.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBf8OwjmeaJr"
      },
      "source": [
        "Let's load this json file containing 5 articles, comprised of maintext, title, date of publishment, and news source."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2F-dco-xOt0",
        "outputId": "c8219655-1543-4944-9361-1c83fdd9e520"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'title': 'American Airlines orders 60 Overture supersonic jets',\n",
              "  'maintext': \"The revival of supersonic passenger travel, thought to be long dead with the demise of Concorde nearly two decades ago, could be about to take wing as American Airlines has put in an order for 60 aircraft capable of flying at 1.7 times the speed of sound. \\nBoom is a start-up based in Denver, Colorado, whose development of Overture, an ultra-fast successor to Concorde that seats 65 to 88 passengers, is so advanced that it showed off designs at last month's Farnborough air show.\",\n",
              "  'date': '2022-08-18',\n",
              "  'source': 'The New York Times'},\n",
              " {'title': \"Conte: 'Chelsea are not in the race to sign Sanchez'\",\n",
              "  'maintext': 'Antonio Conte. Pic: PA\\nHead coach Antonio Conte does not think Chelsea are in the race to sign Arsenal forward Alexis Sanchez.\\nSanchez is out of contract this summer and seemed certain to join Manchester City this month.\\nBut the Premier League leaders on Monday evening decided to end their interest because of the costs involved, with Manchester United in pole position, while there were suggestions the Premier League champions were also in the running.\\nConte last Friday spoke of his admiration for Sanchez and described any potential cut-priced deal for the Chile striker as a great opportunity.\\nThe Italian was evasive when quizzed on Chelsea\\'s interest in the player, taking his usual stance in deferring matters of recruitment to the club.\\nAsked if Chelsea were actively seeking to sign Sanchez, Conte said: \"I don\\'t know. I don\\'t think so. I don\\'t know, but I don\\'t think so.\"\\nConte, speaking ahead of tonight\\'s FA Cup third-round replay at home to Norwich, was reluctant to discuss the transfer market.\\n\"About the transfer market, I prefer to talk to the club, also to give opinions,\" he added.\\nPlanned\\n\"I repeat: I don\\'t want to give my opinion about the transfer market.\"\\nMeanwhile, Daniel Farke says Norwich will have something \"special\" planned for Chelsea tonight.\\nThe Canaries head to Stamford Bridge on the back holding the Premier League champions to a goalless draw at Carrow Road.\\nFarke\\'s men followed that up with a battling 1-0 win at Sky Bet Championship promotion hopefuls Bristol City, who earned great plaudits for their League Cup efforts against Manchester City.\\nThe German believes Norwich will have a free shot at pulling off a shock result in tonight trip to west London and see the winners at home to Newcastle in round four.\\n\"I\\'m hoping for another brilliant performance against one of the giants, and we\\'ll have a special plan for tomorrow,\" Farke said. \"Hopefully with a really good performance and, if Chelsea aren\\'t at their very best, then we\\'ll always have a chance.\\n\"It will be important to keep as much possession as possible, as we don\\'t want to be running after the ball for 90 minutes - so we have to be brave in our possession and our pressing.\"\\nFarke, though, accepts Norwich cannot afford to underestimate the challenge ahead.\\n\"They haven\\'t scored for three games so they will be wanting to show they can score, especially in a home match,\" the Canaries boss added.',\n",
              "  'date': '2018-01-23',\n",
              "  'source': 'The Herald-ir'},\n",
              " {'title': 'Gunman opens fire on car just metres from scene of Hamid Sanambar murder',\n",
              "  'maintext': 'Hamid Sanambar\\nGardai are hunting for a gunman who opened fire on a car in north Dublin - just metres from where Hamid Sanambar was gunned down last week.\\nEmergency services were alerted to reports of gunfire in Kilmore Road in the Artane area of the capital shortly before 9pm on Wednesday.\\nGardai believe a number of rounds were fired at the car before the gunman and the vehicle fled the scene.\\nFled\\nDetectives investigating the shooting are probing if the gunman interacted with the car driver before he opened fire.\\nIt is understood the gunman fled the area on foot.\\nThe incident happened just a few hundred metres from Kilbarron Avenue where Sanambar (41) was shot dead on Wednesday of last week.\\nGardai said investigations into that shooting are still ongoing.\\n\"Gardai are investigating reports of an alleged shooting incident on the Kilmore Road, Artane, Dublin 5,\" a spokeswoman said.\\n\"The incident occurred on June 5, 2019, at approximately 8.50pm.\\n\"No injuries were reported and investigations are ongoing.\"\\nThe area has been plagued by a number of gun attacks in recent weeks, including two murders.\\nA third person from the suburb, Sean Little (22), was shot dead in Balbriggan last month.\\nEarlier this week, Justice Minister Charlie Flanagan visited Coolock in north Dublin amid escalating gangland violence.\\nMr Flanagan repeatedly described the youngsters involved in the violence as \"losers\".\\nHe encouraged young people in the area to \"forget about the bling\".\\nDRUGS\\n\"My message to young people in this area is that there is no future in organised crime or drugs or the associated bling that that brings,\" he told the media as he arrived at Coolock Garda Station.\\n\"These are losers and I\\'m calling on the community to work closely with gardai to ensure that the challenge can be surmounted.\"\\nThe minister said there were about 100 people are involved in serious crime in the Coolock area.',\n",
              "  'date': '2019-06-07',\n",
              "  'source': 'The Herald-ir'},\n",
              " {'title': \"'One-punch killer's sentence will make others think twice'\",\n",
              "  'maintext': 'Luke O\\'Reilly with his mother Janet O\\'Brien Luke O\\'Reilly Jack Hall Ellis The Metro One Bar in Tallaght, where Hall Ellis had earlier accused Luke O\\'Reilly of talking to his girlfriend\\nThe mother of a young Dublin man who lost his life following a one-punch attack hopes the sentence her son\\'s killer was handed down will act as a deterrent for others.\\nJack Hall Ellis (21) was yesterday jailed for five years after pleading guilty to the manslaughter of Luke O\\'Reilly in Tallaght almost two years ago.\\nHall Ellis, who was on bail at the time over an alleged violent disorder incident, struck the 20-year-old with a single punch, which resulted in Mr O\\'Reilly hitting his head on the ground and suffering fatal injuries.\\nJudge Melanie Greally remarked that single-punch assaults leading to traumatic brain injuries are recurring on the courts\\' case load.\\nLast night, Mr O\\'Reilly\\'s mother, Janet O\\'Brien, told the Herald she was satisfied the judge recognised that such serious assaults were being carried out regularly.\\n\"If he didn\\'t get that punch he would never have hit the ground and died,\" Ms O\\'Brien said.\\nDeterrent\\n\"I was pleased the judge recognised the fact that there are so many of these one-punch attacks. I don\\'t know how many I have heard of since Luke, or parents who have got in touch that have been there before me.\"\\nMr O\\'Reilly\\'s mother described the five-year term given to Hall Ellis as \"a realistic sentence\" and added that, as a result, he would not simply walk away from the killing.\\n\"Hopefully it will make people sit up and listen, and they\\'ll think twice. It will act as a deterrent for kids going around trying to act the hard man, because as I said it doesn\\'t make much difference to us now,\" she added.\\nOn Halloween night in 2017, Mr O\\'Reilly was socialising in the Metro One Bar in Tallaght when Hall Ellis approached him and accused Luke of talking to his girlfriend.\\nEarly the following morning, Mr O\\'Reilly was walking along the Old Blessington Road when he was punched once from behind by Hall Ellis, who had drunk up to 20 shots on the night of the attack.\\nThe victim fell to the ground and hit his head on the concrete pavement. He suffered traumatic brain injuries and tragically passed away 13 days later at Beaumont Hospital.\\nIn a moving victim impact statement, Mr O\\'Reilly\\'s mother said that her family would never be the same following her son\\'s death.\\n\"No family occasion will ever be 100pc joyous again. Every birthday, seasonal holiday or any occasion is just a reminder that Luke\\'s not here to celebrate any of these with us. He should be here,\" Ms O\\'Brien said.\\nShe described how the birth of Luke, just after midnight on August 2, 1997, filled her life with \"unconditional love and unimaginable sense of pride\" that she would get to rear and guide his life so that he too could one day raise his own family.\\nThis, however, was taken away from Ms O\\'Brien by what she described as a \"cowardly\" attack by Hall Ellis.\\n\"I don\\'t believe Jack intended the outcome of his actions for Luke to lose his life, but ultimately this was the result of his actions.\\n\"I also believe that if Jack had abided by his bail conditions my son would be alive here with us today,\" she told the court, in reference to the fact that Hall Ellis had breached a curfew and a bond to keep the peace on the night of the fatal assault.\\nMs O\\'Brien also described as \"gut wrenching\" the fact that the accused presented himself to gardai only after he realised that Mr O\\'Reilly was not expected to survive.\\nShe recalled being informed by medical staff at Beaumont Hospital on the morning of November 13, 2017, that Mr O\\'Reilly was not going to recover from the assault, and making the decision to donate her son\\'s organs.\\n\"I climbed into bed beside him, hugging on to his warm body, never wanting to let go and listening to his beating heart that was now only beating to save someone else\\'s life,\" Ms O\\'Brien said.\\nJudge Greally said that Hall Ellis attributed his actions to anger and drunkenness, having previously heard that he consumed between seven and 10 double Captain Morgans that night.\\nThe court heard the accused had nine previous convictions, eight of which were for road traffic offences and one related to possession of drugs.\\nJudge Greally said she was handed a picture of Luke which she said was a \"poignant image\" of him in his youth, and that he was a \"special young man who was deeply loved by his family\".\\nSentencing Hall Ellis, the judge said the aggravating factors included the unprovoked nature of the assault, that he breached bail conditions on the night of the assault, and that even though he observed Luke motionless on the ground, he still decided to leave the scene.\\nShe gave him credit for his early guilty plea, his absence of previous violent conduct and his genuine remorse, before jailing him for seven years with the final two suspended.',\n",
              "  'date': '2019-06-29',\n",
              "  'source': 'The Herald-ir'},\n",
              " {'title': 'Leclerc dedicates win to Hubert',\n",
              "  'maintext': 'Charles Leclerc\\nCharles Leclerc registered the maiden win of his Formula One career after romping to victory at the Belgian Grand Prix.\\nLess than 24 hours after Leclerc\\'s French motor racing contemporary, Anthoine Hubert, was killed at the Spa-Francorchamps venue, the young Monegasque driver delivered a dominant display to take the chequered flag in his friend\\'s honour.\\nLewis Hamilton finished second after fighting his way past Sebastian Vettel with 12 laps remaining.\\nHamilton\\'s Mercedes team-mate Valtteri Bottas also managed to see off Vettel after the Ferrari driver was forced to make an additional stop for tyres.\\nHamilton extended his lead over Bottas in the championship to 65 points.\\n\"This one is for Anthoine,\" said an emotional Leclerc on the radio.\\n\"It feels good but it is difficult to enjoy a weekend like this.\\n\"On one hand I have realised a dream, but on the other hand it has been a difficult weekend.\\n\"I have lost a friend, so I would like to dedicate my win to him.\\n\"We have grown up together. It is a shame what happened yesterday, so I cannot enjoy my first victory.\"\\nLeclerc posted a childhood picture with his arm around Hubert upon news of his death following a horrifying 257kmh crash in Saturday\\'s Formula Two race.\\nHe accompanied the picture with the words: \"I can\\'t believe it.\"\\nThe Ferrari driver, who is 22 next month, the same age as Hubert, was visibly moved by the tragedy.\\nPrior to the race, he hugged Hubert\\'s mother, Nathalie.\\nA moment of silence was observed before the race in the French driver\\'s memory. Nathalie held her son\\'s pink and white crash helmet. Hubert\\'s brother, Victhor, stood alongside her as the Formula One and grieving Formula Two drivers formed an arc, bowing their heads in honour of their fallen colleague.\\nAll 20 of the drivers\\' cars yesterday were adorned with \"Racing for Anthoine\" stickers.',\n",
              "  'date': '2019-09-01',\n",
              "  'source': 'The Herald-ir'}]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "with open(\"5articles.json\", \"r\") as f:\n",
        "    articles = json.load(f)\n",
        "\n",
        "articles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHFdXiwJf3z_"
      },
      "source": [
        "## Simple bag-of-words vectorizers (Count and TF-IDF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lZ36C5GnyNcj"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer # Just counts the occurrences of terms\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnCqny37elPn"
      },
      "source": [
        "Let's make a simple test, and use CountVectorizer and TFIDF Vectorizer on the titles (5 tot documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ysEgLx4ZskA5"
      },
      "outputs": [],
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(input='content')\n",
        "count_vectorizer = CountVectorizer(input='content')\n",
        "titles = [a[\"title\"] for a in articles]\n",
        "tfidf_vectors = tfidf_vectorizer.fit_transform(titles)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtLh2VJ675KS"
      },
      "outputs": [],
      "source": [
        "tfidf_vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqoCPU5d8kqW",
        "outputId": "3f99f3b8-1048-4052-98b4-c05eb21d70ba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "unique_tokens = {}\n",
        "for title in titles:\n",
        "  tokens = title.split()\n",
        "  for token in tokens:\n",
        "    if token not in unique_tokens:\n",
        "      unique_tokens[token] = 1\n",
        "    else:\n",
        "      unique_tokens[token] = unique_tokens[token] + 1\n",
        "\n",
        "len(unique_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BfGAXyr_hRF",
        "outputId": "3c2f439f-3141-4d37-9871-44273d9a669e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'american': 1,\n",
              " 'airlines': 1,\n",
              " 'orders': 1,\n",
              " '60': 1,\n",
              " 'overture': 1,\n",
              " 'supersonic': 1,\n",
              " 'jets': 1,\n",
              " 'conte:': 1,\n",
              " \"'chelsea\": 1,\n",
              " 'are': 1,\n",
              " 'not': 1,\n",
              " 'in': 1,\n",
              " 'the': 1,\n",
              " 'race': 1,\n",
              " 'to': 2,\n",
              " 'sign': 1,\n",
              " \"sanchez'\": 1,\n",
              " 'gunman': 1,\n",
              " 'opens': 1,\n",
              " 'fire': 1,\n",
              " 'on': 1,\n",
              " 'car': 1,\n",
              " 'just': 1,\n",
              " 'metres': 1,\n",
              " 'from': 1,\n",
              " 'scene': 1,\n",
              " 'of': 1,\n",
              " 'hamid': 1,\n",
              " 'sanambar': 1,\n",
              " 'murder': 1,\n",
              " \"'one-punch\": 1,\n",
              " \"killer's\": 1,\n",
              " 'sentence': 1,\n",
              " 'will': 1,\n",
              " 'make': 1,\n",
              " 'others': 1,\n",
              " 'think': 1,\n",
              " \"twice'\": 1,\n",
              " 'leclerc': 1,\n",
              " 'dedicates': 1,\n",
              " 'win': 1,\n",
              " 'hubert': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "unique_tokens = {}\n",
        "for title in titles:\n",
        "  tokens = title.split()\n",
        "  for token in tokens:\n",
        "      token = token.lower()\n",
        "      prev_count = unique_tokens.get(token, 0)\n",
        "      unique_tokens[token] = prev_count + 1\n",
        "\n",
        "len(unique_tokens)\n",
        "unique_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0u82qzY_MuT",
        "outputId": "c2754cf2-2e84-4dc5-b017-114e8eb4caa7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "len(list(tfidf_vectorizer.get_feature_names_out()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EM1qkKSzCJR_",
        "outputId": "a9076cfc-6dc6-4f85-9f5d-45f70daf272c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['chelsea', 'conte', 'killer', 'one', 'punch', 'sanchez', 'twice']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "list_of_features = list(tfidf_vectorizer.get_feature_names_out())\n",
        "[w for w in list_of_features if w not in unique_tokens.keys()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iz2kx8D_Cn62",
        "outputId": "6dd4cba1-5cad-4e27-d6a4-f8b94aa48688"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "unique_tokens[\"conte:\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyLyy6ggerT-"
      },
      "source": [
        "Let's report now the TFIDF of the words, writing in a specific row (\"\\_\\_Document Frequency\\_\\_\") the number of times said \"token\" appears over all documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "gSaS7w2gymY5",
        "outputId": "02a918a2-321b-403d-92d1-ccc700290351"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    airlines  chelsea   car  \\\n",
              "'One-punch killer's sentence will make others t...      0.00     0.00  0.00   \n",
              "American Airlines orders 60 Overture supersonic...      0.38     0.00  0.00   \n",
              "Conte: 'Chelsea are not in the race to sign San...      0.00     0.32  0.00   \n",
              "Gunman opens fire on car just metres from scene...      0.00     0.00  0.28   \n",
              "Leclerc dedicates win to Hubert                         0.00     0.00  0.00   \n",
              "__Document Frequency__                                  1.00     1.00  1.00   \n",
              "\n",
              "                                                    murder  think   one   the  \\\n",
              "'One-punch killer's sentence will make others t...    0.00   0.33  0.33  0.00   \n",
              "American Airlines orders 60 Overture supersonic...    0.00   0.00  0.00  0.00   \n",
              "Conte: 'Chelsea are not in the race to sign San...    0.00   0.00  0.00  0.32   \n",
              "Gunman opens fire on car just metres from scene...    0.28   0.00  0.00  0.00   \n",
              "Leclerc dedicates win to Hubert                       0.00   0.00  0.00  0.00   \n",
              "__Document Frequency__                                1.00   1.00  1.00  1.00   \n",
              "\n",
              "                                                      to  \n",
              "'One-punch killer's sentence will make others t...  0.00  \n",
              "American Airlines orders 60 Overture supersonic...  0.00  \n",
              "Conte: 'Chelsea are not in the race to sign San...  0.26  \n",
              "Gunman opens fire on car just metres from scene...  0.00  \n",
              "Leclerc dedicates win to Hubert                     0.37  \n",
              "__Document Frequency__                              2.00  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9a779fbe-1d16-4e1a-be76-7d5ddfe62200\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airlines</th>\n",
              "      <th>chelsea</th>\n",
              "      <th>car</th>\n",
              "      <th>murder</th>\n",
              "      <th>think</th>\n",
              "      <th>one</th>\n",
              "      <th>the</th>\n",
              "      <th>to</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>'One-punch killer's sentence will make others think twice'</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>American Airlines orders 60 Overture supersonic jets</th>\n",
              "      <td>0.38</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Conte: 'Chelsea are not in the race to sign Sanchez'</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gunman opens fire on car just metres from scene of Hamid Sanambar murder</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Leclerc dedicates win to Hubert</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>__Document Frequency__</th>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>2.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9a779fbe-1d16-4e1a-be76-7d5ddfe62200')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9a779fbe-1d16-4e1a-be76-7d5ddfe62200 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9a779fbe-1d16-4e1a-be76-7d5ddfe62200');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"tfidf_df[['airlines', 'chelsea', 'car', 'murder', 'think', 'one','the', 'to']]\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"airlines\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4066939881532551,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0,\n          0.38,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chelsea\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4029888335921977,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0,\n          0.32,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"car\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4013311184877976,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0,\n          0.28,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"murder\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4013311184877976,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0,\n          0.28,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"think\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.40350547290794786,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.33,\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"one\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.40350547290794786,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.33,\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"the\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4029888335921977,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0,\n          0.32,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"to\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7812404666085,\n        \"min\": 0.0,\n        \"max\": 2.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.26,\n          2.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "import pandas as pd\n",
        "tfidf_df = pd.DataFrame(tfidf_vectors.toarray(), index=titles, columns=tfidf_vectorizer.get_feature_names_out())\n",
        "tfidf_df.loc['__Document Frequency__'] = (tfidf_df > 0).sum()\n",
        "tfidf_df[['airlines', 'chelsea', 'car', 'murder', 'think', 'one','the', 'to']].sort_index().round(decimals=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-QI6MqPe7wo"
      },
      "source": [
        "Let's define a function that reports the top n words by count score (countvectorizer) and TFIDF score in the collection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "GA2opo6vz6Ma"
      },
      "outputs": [],
      "source": [
        "def get_top_n_words(documents, tfidf_vectorizer, count_vectorizer, top_n = 10):\n",
        "  tfidf_vectors, count_vectors = tfidf_vectorizer.fit_transform(documents), count_vectorizer.fit_transform(documents)\n",
        "  feature_names_tfidf, feature_names_count = tfidf_vectorizer.get_feature_names_out(), count_vectorizer.get_feature_names_out()\n",
        "  top_indices_tfidf, top_indices_count = np.argsort(tfidf_vectors.data)[:-(top_n):-1], np.argsort(count_vectors.data)[:-(top_n):-1]\n",
        "  print(\"TFIDF       -        COUNT\")\n",
        "  for tfidx, cidx in zip(top_indices_tfidf, top_indices_count):\n",
        "    print(\"{} ({}) - {} ({})\".format(feature_names_tfidf[tfidf_vectors.indices[tfidx]], round(tfidf_vectors.data[tfidx]*100)/100, feature_names_count[count_vectors.indices[cidx]], count_vectors.data[cidx]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idsaWlNzfELZ"
      },
      "source": [
        "Running it on the titles does not make that much sense, let's run it on a bigger corpus (maintexts). The document count is the same (5), but we can expect a larger number of tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IujsMKB8bAN",
        "outputId": "ebde599f-4a2f-4b89-a046-de80c6a6f031"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TFIDF       -        COUNT\n",
            "the (0.5) - the (49)\n",
            "the (0.41) - the (26)\n",
            "the (0.41) - to (25)\n",
            "the (0.38) - the (22)\n",
            "to (0.34) - that (22)\n",
            "of (0.29) - of (21)\n",
            "area (0.24) - to (20)\n",
            "concorde (0.24) - his (20)\n",
            "his (0.24) - and (19)\n",
            "in (0.23) - the (19)\n",
            "to (0.23) - was (17)\n"
          ]
        }
      ],
      "source": [
        "maintexts = [a[\"maintext\"] for a in articles]\n",
        "get_top_n_words(maintexts, tfidf_vectorizer, count_vectorizer, top_n=12)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2v_6pTzvff51"
      },
      "source": [
        "Stopwords get an extremely high score. That is due to the fact that the total document count is extremely low (5), making it impossible for the IDF factor of the formula to properly scale down the scores. In this case, we can simply remove all the stopwords in the collection using the built-in \"stop_words\" parameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8sh2b1P9fox",
        "outputId": "bc8977f4-36d8-4d08-b957-43036f129d15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TFIDF       -        COUNT\n",
            "area (0.34) - reilly (12)\n",
            "reilly (0.33) - luke (11)\n",
            "hubert (0.3) - hall (11)\n",
            "leclerc (0.3) - ellis (11)\n",
            "hall (0.3) - said (9)\n",
            "luke (0.3) - mr (8)\n",
            "ellis (0.3) - brien (7)\n",
            "concorde (0.3) - night (6)\n",
            "chelsea (0.25) - area (6)\n"
          ]
        }
      ],
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(input='content', stop_words=\"english\")\n",
        "count_vectorizer = CountVectorizer(input='content', stop_words=\"english\")\n",
        "get_top_n_words(maintexts, tfidf_vectorizer, count_vectorizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iadVc3KeSJJj",
        "outputId": "b0340cac-a898-457c-82f2-386090d8cf5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-03-01 11:11:32--  https://raw.githubusercontent.com/giusprencunipi/IR-Master/main/data/500news.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 147867 (144K) [text/plain]\n",
            "Saving to: ‘500news.json’\n",
            "\n",
            "\r500news.json          0%[                    ]       0  --.-KB/s               \r500news.json        100%[===================>] 144.40K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2026-03-01 11:11:33 (5.33 MB/s) - ‘500news.json’ saved [147867/147867]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/giusprencunipi/IR-Master/main/data/500news.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5GbpzUbYSUT0",
        "outputId": "fd0513c9-6fc0-4bfd-84dd-1fbfc2455f42"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Victims are civilians: the attacker took his own life'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "with open(\"500news.json\", \"r\") as f:\n",
        "    news = json.load(f)\n",
        "news[0][\"maintext\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdIXFmycSlTg",
        "outputId": "2c5043ae-545a-47e9-9df8-f203255cf9b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TFIDF       -        COUNT\n",
            "regionals (0.98) - the (12)\n",
            "episodeth (0.77) - the (11)\n",
            "research (0.73) - the (11)\n",
            "adjourned (0.67) - the (10)\n",
            "california (0.67) - the (10)\n",
            "38 (0.66) - the (9)\n",
            "progress (0.65) - the (9)\n",
            "happened (0.61) - the (9)\n",
            "february (0.61) - the (9)\n"
          ]
        }
      ],
      "source": [
        "maintexts = [a[\"maintext\"] for a in news]\n",
        "tfidf_vectorizer = TfidfVectorizer(input='content')\n",
        "count_vectorizer = CountVectorizer(input='content')\n",
        "get_top_n_words(maintexts, tfidf_vectorizer, count_vectorizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJ4FbXyUVYpW",
        "outputId": "674712ae-0014-4c76-ec6d-40c99593e3da"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
              "\twith 10383 stored elements and shape (500, 3476)>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "tfidf_vectorizer.fit_transform(maintexts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjeXgOv3gIaJ"
      },
      "source": [
        "let's read the \"Alice in Wonderland\" book, and let's first try to run Count and TF-IDF vectorizers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2CkMzWXgSuD"
      },
      "source": [
        "## Making queries with TF_IDF\n",
        "For queries, we need to also \"vectorize\" the query. Let's try with \"car\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWxGl56FGWHE",
        "outputId": "833943c9-b2fa-4aa6-ccfd-cbf1b3a0ef97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.         0.         0.         0.         0.04565353]\n",
            "Top 3 matching documents with \"cars\":\n",
            "\n",
            "Score: 0.0457 - Charles Leclerc\n",
            "Charles Leclerc registered the maiden win of his Formula One career after romping to victory at the Belgian Grand Prix.\n",
            "Less than 24 hours after Leclerc's French motor racing contempor...\n",
            "\n",
            "Score: 0.0000 - Luke O'Reilly with his mother Janet O'Brien Luke O'Reilly Jack Hall Ellis The Metro One Bar in Tallaght, where Hall Ellis had earlier accused Luke O'Reilly of talking to his girlfriend\n",
            "The mother of a...\n",
            "\n",
            "Score: 0.0000 - Hamid Sanambar\n",
            "Gardai are hunting for a gunman who opened fire on a car in north Dublin - just metres from where Hamid Sanambar was gunned down last week.\n",
            "Emergency services were alerted to reports of...\n"
          ]
        }
      ],
      "source": [
        "query = \"cars\"\n",
        "maintexts = [a[\"maintext\"] for a in articles]\n",
        "tfidf_vectors = tfidf_vectorizer.fit_transform(maintexts) # here we rerun the vectorizer for the maintexts of the articles\n",
        "query_vector = tfidf_vectorizer.transform([query]) # here we create the vector for \"car\"\n",
        "cosine_similarities = cosine_similarity(query_vector, tfidf_vectors).flatten() # compute all cosine similarities\n",
        "print(cosine_similarities)\n",
        "top_indices = np.argsort(cosine_similarities)[::-1][:3] # sort them decreasingly and limit to the top 3 most similar\n",
        "print(\"Top 3 matching documents with \\\"{}\\\":\".format(query))\n",
        "for index in top_indices:\n",
        "    print(f\"\\nScore: {cosine_similarities[index]:.4f} - {maintexts[index][:200]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GS2AKf2gpYG3"
      },
      "source": [
        "Why do we get a 0 score for the \"charles Leclerc\" article (which corresponds to maintexts[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfzN69tXJ2Zb",
        "outputId": "deb378f7-bfae-4686-9dfe-0cc5637b42e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "False\n",
            "False\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "print(\"Car\" in maintexts[4]) # as we see, only \"Car\", with uppercase C, is present in the maintext\n",
        "print(\" car \" in maintexts[4])\n",
        "print(\"Cars\" in maintexts[4]) # as we see, only \"Car\", with uppercase C, is present in the maintext\n",
        "print(\" cars \" in maintexts[4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLh8cSgd5ZTG",
        "outputId": "9403e640-74f5-43e2-b20a-fbd2d2d7d622"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-03-01 11:12:49--  https://raw.githubusercontent.com/giusprencunipi/IR-Master/main/data/alice.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 151255 (148K) [text/plain]\n",
            "Saving to: ‘alice.txt’\n",
            "\n",
            "\ralice.txt             0%[                    ]       0  --.-KB/s               \ralice.txt           100%[===================>] 147.71K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2026-03-01 11:12:49 (7.29 MB/s) - ‘alice.txt’ saved [151255/151255]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/giusprencunipi/IR-Master/main/data/alice.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRr_D0EV5dhy",
        "outputId": "67004caa-295f-48fa-a007-ca94d2a3fa41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"\\ufeff\\ufeff*** start of the project gutenberg ebook alice's adventures in\", 'wonderland ***', '[illustration]', 'alice’s adventures in wonderland', 'by lewis carroll', 'the millennium fulcrum edition 3.0', 'contents', ' chapter i.     down the rabbit-hole', ' chapter ii.    the pool of tears', ' chapter iii.   a caucus-race and a long tale']\n",
            "2498\n",
            "TFIDF       -        COUNT\n",
            "cheered (1.0) - you (5)\n",
            "illustration (1.0) - you (5)\n",
            "wonderland (1.0) - not (5)\n",
            "off (1.0) - not (5)\n",
            "too (1.0) - you (5)\n",
            "sighing (1.0) - the (5)\n",
            "think (1.0) - mouse (5)\n",
            "yourself (1.0) - you (5)\n",
            "chapter (1.0) - the (4)\n"
          ]
        }
      ],
      "source": [
        "with open(\"alice.txt\", 'r') as alice_file:\n",
        "  alice = alice_file.read().lower()\n",
        "sentences = [a for a in alice.split('\\n') if a]\n",
        "print(sentences[:10])\n",
        "print(len(sentences))\n",
        "tfidf_vectorizer = TfidfVectorizer(input='content')\n",
        "count_vectorizer = CountVectorizer(input='content')\n",
        "get_top_n_words(sentences, tfidf_vectorizer, count_vectorizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "x2bq20BfbdF9"
      },
      "outputs": [],
      "source": [
        "def run_query(tfidf_matrix, tfidf_vectorizer, documents, query, top_n=3):\n",
        "  query_vector = tfidf_vectorizer.transform([query])\n",
        "  cosine_similarities = cosine_similarity(query_vector, tfidf_matrix).flatten() # compute all cosine similarities\n",
        "  top_indices = np.argsort(cosine_similarities)[::-1][:top_n]\n",
        "  print(\"Top {} matching documents with \\\"{}\\\":\".format(top_n, query))\n",
        "  for index in top_indices:\n",
        "      print(f\"\\nScore: {cosine_similarities[index]:.4f} - {documents[index][:200]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qA7qxttFZ_ur",
        "outputId": "436fde0b-2c1a-4eb4-85fc-86094e4eaa93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 3 matching documents with \"alice rabbit\":\n",
            "\n",
            "Score: 0.5061 - alice....\n",
            "\n",
            "Score: 0.4960 - down the rabbit-hole...\n",
            "\n",
            "Score: 0.4470 - “we must burn the house down!” said the rabbit’s voice; and alice...\n"
          ]
        }
      ],
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(input='content', stop_words=\"english\")\n",
        "tfidf_vectors = tfidf_vectorizer.fit_transform(sentences)\n",
        "run_query(tfidf_vectors, tfidf_vectorizer, sentences, \"alice rabbit\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4I-pUstmpmlR"
      },
      "source": [
        "This is to show the importance of running proper preprocessing algorithms. Remember lecture 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEBX691Upuub"
      },
      "source": [
        "## BM25, another bag-of-word metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oN55Kh3NzZe",
        "outputId": "ed2e13a5-dada-4e4b-e89a-a5c81261b6eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rank_bm25\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rank_bm25) (2.0.2)\n",
            "Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Installing collected packages: rank_bm25\n",
            "Successfully installed rank_bm25-0.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install rank_bm25\n",
        "from rank_bm25 import BM25Okapi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "xJy6kZpBN4e_"
      },
      "outputs": [],
      "source": [
        "tokenized_corpus = [doc.split() for doc in maintexts]\n",
        "bm25 = BM25Okapi(tokenized_corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvYIJQx0OI3I",
        "outputId": "55b6a0fc-ff9a-4f7b-fecf-a4b9be0bb566"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BM25 score of \"car\"\n",
            "\n",
            "American Airlines orders 60 Overture supersonic jets  -  0.36056091095119297\n",
            "Conte: 'Chelsea are not in the race to sign Sanchez'  -  0.49688407493580367\n",
            "Gunman opens fire on car just metres from scene of Hamid Sanambar murder  -  0.4793952947855894\n",
            "'One-punch killer's sentence will make others think twice'  -  0.4842349898476344\n",
            "Leclerc dedicates win to Hubert  -  0.5021737251539523\n"
          ]
        }
      ],
      "source": [
        "print(\"BM25 score of \\\"car\\\"\\n\")\n",
        "scores = bm25.get_scores(\"car\")\n",
        "for title, score in zip(titles, scores):\n",
        "  print(title, \" - \", score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPXfTttJfxof"
      },
      "source": [
        "## Word Embeddings and word2vec\n",
        "Let's now move to more advanced vectorization techniques. These techinques use Machine Learning and try to learn the patterns in which words tend to co-occur."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DloB3O2zgiVm",
        "outputId": "eac61b86-1aac-49b1-8d99-b86962a5ac8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.1.1)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim\n",
        "import gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFTi-WQEYOkz",
        "outputId": "c981207f-f0e7-4a85-8784-45a2611d5d24"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['“',\n",
              " 'yes',\n",
              " ',',\n",
              " 'but',\n",
              " 'some',\n",
              " 'crumbs',\n",
              " 'must',\n",
              " 'have',\n",
              " 'got',\n",
              " 'in',\n",
              " 'as',\n",
              " 'well',\n",
              " ',',\n",
              " '”',\n",
              " 'the',\n",
              " 'hatter',\n",
              " 'grumbled',\n",
              " ':',\n",
              " '“',\n",
              " 'you',\n",
              " 'shouldn',\n",
              " '’',\n",
              " 't',\n",
              " 'have',\n",
              " 'put',\n",
              " 'it',\n",
              " 'in',\n",
              " 'with',\n",
              " 'the',\n",
              " 'bread-knife.',\n",
              " '”',\n",
              " 'the',\n",
              " 'march',\n",
              " 'hare',\n",
              " 'took',\n",
              " 'the',\n",
              " 'watch',\n",
              " 'and',\n",
              " 'looked',\n",
              " 'at',\n",
              " 'it',\n",
              " 'gloomily',\n",
              " ':',\n",
              " 'then',\n",
              " 'he',\n",
              " 'dipped',\n",
              " 'it',\n",
              " 'into',\n",
              " 'his',\n",
              " 'cup',\n",
              " 'of',\n",
              " 'tea',\n",
              " ',',\n",
              " 'and',\n",
              " 'looked',\n",
              " 'at',\n",
              " 'it',\n",
              " 'again',\n",
              " ':',\n",
              " 'but',\n",
              " 'he',\n",
              " 'could',\n",
              " 'think',\n",
              " 'of',\n",
              " 'nothing',\n",
              " 'better',\n",
              " 'to',\n",
              " 'say',\n",
              " 'than',\n",
              " 'his',\n",
              " 'first',\n",
              " 'remark',\n",
              " ',',\n",
              " '“',\n",
              " 'it',\n",
              " 'was',\n",
              " 'the',\n",
              " '_best_',\n",
              " 'butter',\n",
              " ',',\n",
              " 'you',\n",
              " 'know.',\n",
              " '”',\n",
              " 'alice',\n",
              " 'had',\n",
              " 'been',\n",
              " 'looking',\n",
              " 'over',\n",
              " 'his',\n",
              " 'shoulder',\n",
              " 'with',\n",
              " 'some',\n",
              " 'curiosity',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "alice_tokens = []\n",
        "for sentence in nltk.sent_tokenize(alice):\n",
        "  sentence_tokens = []\n",
        "  for w in word_tokenize(sentence):\n",
        "    sentence_tokens.append(w.lower())\n",
        "  alice_tokens.append(sentence_tokens)\n",
        "alice_tokens[500]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuvJcduYfQCb",
        "outputId": "7c1de623-090f-4da1-bc1f-939ab9059ce5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "981"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "len(alice_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLf_GwsQtNq6"
      },
      "source": [
        "The two models for Word2Vec are CBOW (Continuous Bag of Words Model) and Skip-Gram.\n",
        "CBOW mira a predirre il token i-esimo a partire da una finestra che specifica il suo contesto. Skip-Gram invece svolge il compito opposto (predice il contesto a partire dalla parola corrente)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "UNY42NpxYj_V"
      },
      "outputs": [],
      "source": [
        "# CBOW model\n",
        "cbow_model = gensim.models.Word2Vec(alice_tokens, min_count=1,\n",
        "                                vector_size=100, window=5)\n",
        "# Skip Gram model\n",
        "skipgram_model = gensim.models.Word2Vec(alice_tokens, min_count=1, vector_size=100,\n",
        "                                window=5, sg=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHo0_iHXZFVb",
        "outputId": "20b562d9-b5c5-4a45-9c35-1352a1a6de8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine similarity between 'alice' and 'wonderland' - CBOW :  0.98197067\n",
            "Cosine similarity between 'alice' and 'wonderland' - SkipGram :  0.6709046\n"
          ]
        }
      ],
      "source": [
        "print(\"Cosine similarity between 'alice' \" + \"and 'wonderland' - CBOW : \",\n",
        "      cbow_model.wv.similarity('alice', 'wonderland'))\n",
        "print(\"Cosine similarity between 'alice' \" + \"and 'wonderland' - SkipGram : \",\n",
        "      skipgram_model.wv.similarity('alice', 'wonderland'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IISqEzP7a2XJ",
        "outputId": "da5b1dc8-1be4-4ba4-af2d-067dddca9357"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine similarity between 'alice' and 'gloomily' - CBOW :  0.9539487\n",
            "Cosine similarity between 'alice' and 'gloomily' - SkipGram :  0.88177806\n"
          ]
        }
      ],
      "source": [
        "print(\"Cosine similarity between 'alice' \" + \"and 'gloomily' - CBOW : \",\n",
        "      cbow_model.wv.similarity('alice', 'gloomily'))\n",
        "print(\"Cosine similarity between 'alice' \" + \"and 'gloomily' - SkipGram : \",\n",
        "      skipgram_model.wv.similarity('alice', 'gloomily'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuQVaf3khVwA",
        "outputId": "d368da56-8d27-4682-ddae-54feab520793"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis']\n"
          ]
        }
      ],
      "source": [
        "import gensim.downloader\n",
        "print(list(gensim.downloader.info()['models'].keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MtlKG4gh7Kq",
        "outputId": "c0d331dc-c89a-4103-8ea1-71d310b7fa28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ],
      "source": [
        "word2vec_precomputed_model = gensim.downloader.load('word2vec-google-news-300')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gedh6lYiiGZd",
        "outputId": "54ad5647-11b5-4e3b-996f-225653fc5ca4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('sports', 0.6914728283882141),\n",
              " ('Snooki_wannabes', 0.5916634798049927),\n",
              " ('painkillers_throat_lozenges', 0.5643172264099121),\n",
              " ('racing', 0.5616023540496826),\n",
              " ('sporting', 0.559779703617096),\n",
              " ('athletics', 0.5516576766967773),\n",
              " ('alpine_ski_racing', 0.5514240264892578),\n",
              " ('Pole_vaulting', 0.5459784269332886),\n",
              " ('motorsport', 0.5384281277656555),\n",
              " ('boxing', 0.5330564379692078)]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "word2vec_precomputed_model.most_similar('sport')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEp8gSlIDgsu",
        "outputId": "d5e193a1-4434-4bb8-cfb2-a4eae03e57be"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 0.999674379825592),\n",
              " (':', 0.9996700286865234),\n",
              " ('and', 0.9996694326400757),\n",
              " ('that', 0.9996629357337952),\n",
              " ('“', 0.999659538269043)]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "#get the most similar vector to \"alice\"\n",
        "cbow_model.wv.most_similar('alice', topn=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z85wr3l4QQ-0"
      },
      "source": [
        "Now let's see how to handle phrases on word2vec. This is not the suggested solution, as \"full-phrase\" models like doc2vec have been shown to outperform word2vec.\n",
        "We can handle handle phrases as list of word2vec vectors, and perform some mathematical operations on them (i.e., sum, average, subtract)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "YCwF0PO1QVjB"
      },
      "outputs": [],
      "source": [
        "query_phrase = \"sport in italy\"\n",
        "#sum the vectors of the individual words\n",
        "query_vector_sum = np.zeros(300)\n",
        "for word in query_phrase.split():\n",
        "  query_vector_sum += word2vec_precomputed_model.get_vector(word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFlBusPSfIUV",
        "outputId": "e38a7a84-9c1d-40fb-f27f-0c0cc845d6c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine similarity with 'football' - Google News (SUM) :  0.43777203627070355\n",
            "Cosine similarity with 'hockey' - Google News (SUM) :  0.41549963160203685\n",
            "Cosine similarity with 'politics' - Google News (SUM) :  0.24661070953269673\n"
          ]
        }
      ],
      "source": [
        "print(\"Cosine similarity with 'football' - Google News (SUM) : \",\n",
        "      cosine_similarity([query_vector_sum], [word2vec_precomputed_model.get_vector(\"football\")])[0][0])\n",
        "print(\"Cosine similarity with 'hockey' - Google News (SUM) : \",\n",
        "      cosine_similarity([query_vector_sum], [word2vec_precomputed_model.get_vector('hockey')])[0][0])\n",
        "print(\"Cosine similarity with 'politics' - Google News (SUM) : \",\n",
        "      cosine_similarity([query_vector_sum], [word2vec_precomputed_model.get_vector('politics')])[0][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLC0NJLmtsor"
      },
      "source": [
        "## Other types of embeddings (Entity and Graph embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSEKtMwXhDiG"
      },
      "source": [
        "And we can also apply this concept to entity embeddings, using Wikipedia as a backend"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WPeBNWkrhJy2"
      },
      "outputs": [],
      "source": [
        "!pip install wikipedia2vec\n",
        "!wget https://raw.githubusercontent.com/LorenzoBellomo/InformationRetrieval/refs/heads/main/data/enwiki_20180420_100d_part.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QlTf29tJiDg_"
      },
      "outputs": [],
      "source": [
        "from wikipedia2vec import Wikipedia2Vec\n",
        "wiki2vec = Wikipedia2Vec.load_text(\"enwiki_20180420_100d_part.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFQ_SMhmqpdz"
      },
      "outputs": [],
      "source": [
        "wiki2vec.most_similar(wiki2vec.get_word('the'), 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1zigxzpqwdr"
      },
      "outputs": [],
      "source": [
        "wiki2vec.most_similar(wiki2vec.get_word('biology'), 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfaDGd48rcRk"
      },
      "source": [
        "And also Embeddings for Graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "embzdivWrfM6"
      },
      "outputs": [],
      "source": [
        "!pip install networkx node2vec\n",
        "import networkx as nx\n",
        "from node2vec import Node2Vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oRj6w6yscSU"
      },
      "source": [
        "Random walks with a length of 30 and a total number of walks equal to 200."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4b2QjAirozr"
      },
      "outputs": [],
      "source": [
        "G = nx.fast_gnp_random_graph(n=100, p=0.5)\n",
        "node2vec = Node2Vec(G, dimensions=64, walk_length=30, num_walks=200, workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WyL5b0vTsW5h"
      },
      "outputs": [],
      "source": [
        "model = node2vec.fit(window=10, min_count=1, batch_words=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUFG0AzZsndl"
      },
      "outputs": [],
      "source": [
        "model.wv.save_word2vec_format(\"embeddings_node2vec.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBOFX7gSsopE"
      },
      "outputs": [],
      "source": [
        "embeddings = {str(node): model.wv[str(node)] for node in G.nodes()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16SXDiI9ssDU"
      },
      "outputs": [],
      "source": [
        "embeddings[\"0\"]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}