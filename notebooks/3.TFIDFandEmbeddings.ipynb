{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LorenzoBellomo/InformationRetrieval/blob/main/notebooks/2_TFIDFandEmbeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmm4PBxppLmM"
      },
      "source": [
        "# Text processing with vectors\n",
        "In this lecture we focus on techinques that allow to model the text as vectors of floating point numbers. This allows us to easily process and compute similarities between words, sentences, and documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfJQqUBQroYR",
        "outputId": "f4c46222-d4e6-4a3f-d389-09ff18a5785d"
      },
      "outputs": [],
      "source": [
        "!pip install scikit-learn\n",
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64D0vyV7se0x",
        "outputId": "131c2912-e6e6-4e5f-8950-9092edfe149a"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ylr9BKyosL9e",
        "outputId": "e4104fe2-260c-4f87-a538-401aac1305b3"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/LorenzoBellomo/InformationRetrieval/refs/heads/main/data/5articles.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBf8OwjmeaJr"
      },
      "source": [
        "Let's load this json file containing 5 articles, comprised of maintext, title, date of publishment, and news source."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2F-dco-xOt0",
        "outputId": "15e82048-2549-4d8f-db2f-53e61a64ec4c"
      },
      "outputs": [],
      "source": [
        "with open(\"5articles.json\", \"r\") as f:\n",
        "    articles = json.load(f)\n",
        "\n",
        "articles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHFdXiwJf3z_"
      },
      "source": [
        "## Simple bag-of-words vectorizers (Count and TF-IDF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "lZ36C5GnyNcj"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer # Just counts the occurrences of terms\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnCqny37elPn"
      },
      "source": [
        "Let's make a simple test, and use CountVectorizer and TFIDF Vectorizer on the titles (5 tot documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ysEgLx4ZskA5"
      },
      "outputs": [],
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(input='content')\n",
        "count_vectorizer = CountVectorizer(input='content')\n",
        "titles = [a[\"title\"] for a in articles]\n",
        "tfidf_vectors = tfidf_vectorizer.fit_transform(titles)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtLh2VJ675KS",
        "outputId": "cfdb1e96-217d-4115-da63-e461c2c72b76"
      },
      "outputs": [],
      "source": [
        "tfidf_vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqoCPU5d8kqW",
        "outputId": "11785392-8193-41e7-97c8-e640b37994a8"
      },
      "outputs": [],
      "source": [
        "unique_tokens = {}\n",
        "for title in titles:\n",
        "  tokens = title.split()\n",
        "  for token in tokens:\n",
        "    if token not in unique_tokens:\n",
        "      unique_tokens[token] = 1\n",
        "    else:\n",
        "      unique_tokens[token] = unique_tokens[token] + 1\n",
        "\n",
        "len(unique_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BfGAXyr_hRF",
        "outputId": "5ddd31af-2966-4b3c-e721-90952c9b1230"
      },
      "outputs": [],
      "source": [
        "unique_tokens = {}\n",
        "for title in titles:\n",
        "  tokens = title.split()\n",
        "  for token in tokens:\n",
        "      token = token.lower()\n",
        "      prev_count = unique_tokens.get(token, 0)\n",
        "      unique_tokens[token] = prev_count + 1\n",
        "\n",
        "len(unique_tokens)\n",
        "unique_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0u82qzY_MuT",
        "outputId": "a625e5b5-afd2-4133-c42f-c243f8766615"
      },
      "outputs": [],
      "source": [
        "len(list(tfidf_vectorizer.get_feature_names_out()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EM1qkKSzCJR_",
        "outputId": "c3ba5d6f-fc53-4f97-d5cc-2434ee662744"
      },
      "outputs": [],
      "source": [
        "list_of_features = list(tfidf_vectorizer.get_feature_names_out())\n",
        "[w for w in list_of_features if w not in unique_tokens.keys()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iz2kx8D_Cn62",
        "outputId": "7d0facf0-b3ca-4d14-9723-149d39cdf08a"
      },
      "outputs": [],
      "source": [
        "unique_tokens[\"conte:\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyLyy6ggerT-"
      },
      "source": [
        "Let's report now the TFIDF of the words, writing in a specific row (\"\\_\\_Document Frequency\\_\\_\") the number of times said \"token\" appears over all documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "gSaS7w2gymY5",
        "outputId": "1c405aa5-7d40-4c76-ab28-f390b59b6fc1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "tfidf_df = pd.DataFrame(tfidf_vectors.toarray(), index=titles, columns=tfidf_vectorizer.get_feature_names_out())\n",
        "tfidf_df.loc['__Document Frequency__'] = (tfidf_df > 0).sum()\n",
        "tfidf_df[['airlines', 'chelsea', 'car', 'murder', 'think', 'one','the', 'to']].sort_index().round(decimals=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-QI6MqPe7wo"
      },
      "source": [
        "Let's define a function that reports the top n words by count score (countvectorizer) and TFIDF score in the collection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "GA2opo6vz6Ma"
      },
      "outputs": [],
      "source": [
        "def get_top_n_words(documents, tfidf_vectorizer, count_vectorizer, top_n = 10):\n",
        "  tfidf_vectors, count_vectors = tfidf_vectorizer.fit_transform(documents), count_vectorizer.fit_transform(documents)\n",
        "  feature_names_tfidf, feature_names_count = tfidf_vectorizer.get_feature_names_out(), count_vectorizer.get_feature_names_out()\n",
        "  top_indices_tfidf, top_indices_count = np.argsort(tfidf_vectors.data)[:-(top_n):-1], np.argsort(count_vectors.data)[:-(top_n):-1]\n",
        "  print(\"TFIDF       -        COUNT\")\n",
        "  for tfidx, cidx in zip(top_indices_tfidf, top_indices_count):\n",
        "    print(\"{} ({}) - {} ({})\".format(feature_names_tfidf[tfidf_vectors.indices[tfidx]], round(tfidf_vectors.data[tfidx]*100)/100, feature_names_count[count_vectors.indices[cidx]], count_vectors.data[cidx]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idsaWlNzfELZ"
      },
      "source": [
        "Running it on the titles does not make that much sense, let's run it on a bigger corpus (maintexts). The document count is the same (5), but we can expect a larger number of tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IujsMKB8bAN",
        "outputId": "c1f83f3d-6eea-4bbf-9867-e50ef4c01045"
      },
      "outputs": [],
      "source": [
        "maintexts = [a[\"maintext\"] for a in articles]\n",
        "get_top_n_words(maintexts, tfidf_vectorizer, count_vectorizer, top_n=12)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2v_6pTzvff51"
      },
      "source": [
        "Stopwords get an extremely high score. That is due to the fact that the total document count is extremely low (5), making it impossible for the IDF factor of the formula to properly scale down the scores. In this case, we can simply remove all the stopwords in the collection using the built-in \"stop_words\" parameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8sh2b1P9fox",
        "outputId": "792155d1-9174-4848-f16e-4d87431e5ac6"
      },
      "outputs": [],
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(input='content', stop_words=\"english\")\n",
        "count_vectorizer = CountVectorizer(input='content', stop_words=\"english\")\n",
        "get_top_n_words(maintexts, tfidf_vectorizer, count_vectorizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iadVc3KeSJJj",
        "outputId": "0671fc88-ff77-4274-adc8-6004ead43bf9"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/LorenzoBellomo/InformationRetrieval/refs/heads/main/data/500news.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5GbpzUbYSUT0",
        "outputId": "4bdfd059-9322-4a8b-d8ff-09552613a657"
      },
      "outputs": [],
      "source": [
        "with open(\"500news.json\", \"r\") as f:\n",
        "    news = json.load(f)\n",
        "news[0][\"maintext\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdIXFmycSlTg",
        "outputId": "52a165aa-350b-4315-befb-dd9d02d6cba9"
      },
      "outputs": [],
      "source": [
        "maintexts = [a[\"maintext\"] for a in news]\n",
        "tfidf_vectorizer = TfidfVectorizer(input='content')\n",
        "count_vectorizer = CountVectorizer(input='content')\n",
        "get_top_n_words(maintexts, tfidf_vectorizer, count_vectorizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJ4FbXyUVYpW",
        "outputId": "3a70110a-595d-4ae4-bd27-d0d99e0ef05d"
      },
      "outputs": [],
      "source": [
        "tfidf_vectorizer.fit_transform(maintexts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjeXgOv3gIaJ"
      },
      "source": [
        "let's read the \"Alice in Wonderland\" book, and let's first try to run Count and TF-IDF vectorizers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2CkMzWXgSuD"
      },
      "source": [
        "## Making queries with TF_IDF\n",
        "For queries, we need to also \"vectorize\" the query. Let's try with \"car\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWxGl56FGWHE",
        "outputId": "e9b38064-5d53-4835-c447-e5d563529151"
      },
      "outputs": [],
      "source": [
        "query = \"cars\"\n",
        "maintexts = [a[\"maintext\"] for a in articles]\n",
        "tfidf_vectors = tfidf_vectorizer.fit_transform(maintexts) # here we rerun the vectorizer for the maintexts of the articles\n",
        "query_vector = tfidf_vectorizer.transform([query]) # here we create the vector for \"car\"\n",
        "cosine_similarities = cosine_similarity(query_vector, tfidf_vectors).flatten() # compute all cosine similarities\n",
        "print(cosine_similarities)\n",
        "top_indices = np.argsort(cosine_similarities)[::-1][:3] # sort them decreasingly and limit to the top 3 most similar\n",
        "print(\"Top 3 matching documents with \\\"{}\\\":\".format(query))\n",
        "for index in top_indices:\n",
        "    print(f\"\\nScore: {cosine_similarities[index]:.4f} - {maintexts[index][:200]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GS2AKf2gpYG3"
      },
      "source": [
        "Why do we get a 0 score for the \"charles Leclerc\" article (which corresponds to maintexts[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfzN69tXJ2Zb",
        "outputId": "9bb8a2d5-f948-4a7f-a4fc-95d70ad7b87a"
      },
      "outputs": [],
      "source": [
        "print(\"Car\" in maintexts[4]) # as we see, only \"Car\", with uppercase C, is present in the maintext\n",
        "print(\" car \" in maintexts[4])\n",
        "print(\"Cars\" in maintexts[4]) # as we see, only \"Car\", with uppercase C, is present in the maintext\n",
        "print(\" cars \" in maintexts[4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLh8cSgd5ZTG",
        "outputId": "048e2c8b-a2ad-465b-b648-e18f2c77db3c"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/LorenzoBellomo/InformationRetrieval/refs/heads/main/data/alice.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRr_D0EV5dhy",
        "outputId": "2dd819fe-0cb4-4070-fe11-4ab21bb08a6a"
      },
      "outputs": [],
      "source": [
        "with open(\"alice.txt\", 'r') as alice_file:\n",
        "  alice = alice_file.read().lower()\n",
        "sentences = [a for a in alice.split('\\n') if a]\n",
        "print(sentences[:10])\n",
        "print(len(sentences))\n",
        "tfidf_vectorizer = TfidfVectorizer(input='content')\n",
        "count_vectorizer = CountVectorizer(input='content')\n",
        "get_top_n_words(sentences, tfidf_vectorizer, count_vectorizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "x2bq20BfbdF9"
      },
      "outputs": [],
      "source": [
        "def run_query(tfidf_matrix, tfidf_vectorizer, documents, query, top_n=3):\n",
        "  query_vector = tfidf_vectorizer.transform([query])\n",
        "  cosine_similarities = cosine_similarity(query_vector, tfidf_matrix).flatten() # compute all cosine similarities\n",
        "  top_indices = np.argsort(cosine_similarities)[::-1][:top_n]\n",
        "  print(\"Top {} matching documents with \\\"{}\\\":\".format(top_n, query))\n",
        "  for index in top_indices:\n",
        "      print(f\"\\nScore: {cosine_similarities[index]:.4f} - {documents[index][:200]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qA7qxttFZ_ur",
        "outputId": "c90d8a17-a8f9-496b-c28e-f3cbc4aa778a"
      },
      "outputs": [],
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(input='content', stop_words=\"english\")\n",
        "tfidf_vectors = tfidf_vectorizer.fit_transform(sentences)\n",
        "run_query(tfidf_vectors, tfidf_vectorizer, sentences, \"alice rabbit\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4I-pUstmpmlR"
      },
      "source": [
        "This is to show the importance of running proper preprocessing algorithms. Remember lecture 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEBX691Upuub"
      },
      "source": [
        "## BM25, another bag-of-word metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oN55Kh3NzZe",
        "outputId": "c8608995-a868-48a6-ab4d-262fe131b833"
      },
      "outputs": [],
      "source": [
        "!pip install rank_bm25\n",
        "from rank_bm25 import BM25Okapi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "xJy6kZpBN4e_"
      },
      "outputs": [],
      "source": [
        "tokenized_corpus = [doc.split() for doc in maintexts]\n",
        "bm25 = BM25Okapi(tokenized_corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvYIJQx0OI3I",
        "outputId": "fdae2298-471f-49ae-b222-5b57bfcfbc4b"
      },
      "outputs": [],
      "source": [
        "print(\"BM25 score of \\\"car\\\"\\n\")\n",
        "scores = bm25.get_scores(\"car\")\n",
        "for title, score in zip(titles, scores):\n",
        "  print(title, \" - \", score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPXfTttJfxof"
      },
      "source": [
        "## Word Embeddings and word2vec\n",
        "Let's now move to more advanced vectorization techniques. These techinques use Machine Learning and try to learn the patterns in which words tend to co-occur."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DloB3O2zgiVm",
        "outputId": "c1e40664-5785-4544-99dd-7ba518674ef1"
      },
      "outputs": [],
      "source": [
        "!pip install gensim\n",
        "import gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFTi-WQEYOkz",
        "outputId": "aba53949-9972-4717-ae02-9374f78a3280"
      },
      "outputs": [],
      "source": [
        "alice_tokens = []\n",
        "for sentence in nltk.sent_tokenize(alice):\n",
        "  sentence_tokens = []\n",
        "  for w in word_tokenize(sentence):\n",
        "    sentence_tokens.append(w.lower())\n",
        "  alice_tokens.append(sentence_tokens)\n",
        "alice_tokens[500]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuvJcduYfQCb",
        "outputId": "c9290912-83f7-425a-f2f4-c323660aa9dd"
      },
      "outputs": [],
      "source": [
        "len(alice_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLf_GwsQtNq6"
      },
      "source": [
        "The two models for Word2Vec are CBOW (Continuous Bag of Words Model) and Skip-Gram.\n",
        "CBOW mira a predirre il token i-esimo a partire da una finestra che specifica il suo contesto. Skip-Gram invece svolge il compito opposto (predice il contesto a partire dalla parola corrente)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "UNY42NpxYj_V"
      },
      "outputs": [],
      "source": [
        "# CBOW model\n",
        "cbow_model = gensim.models.Word2Vec(alice_tokens, min_count=1,\n",
        "                                vector_size=100, window=5)\n",
        "# Skip Gram model\n",
        "skipgram_model = gensim.models.Word2Vec(alice_tokens, min_count=1, vector_size=100,\n",
        "                                window=5, sg=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHo0_iHXZFVb",
        "outputId": "b049634c-3396-48bc-fa44-2132e2d1d767"
      },
      "outputs": [],
      "source": [
        "print(\"Cosine similarity between 'alice' \" + \"and 'wonderland' - CBOW : \",\n",
        "      cbow_model.wv.similarity('alice', 'wonderland'))\n",
        "print(\"Cosine similarity between 'alice' \" + \"and 'wonderland' - SkipGram : \",\n",
        "      skipgram_model.wv.similarity('alice', 'wonderland'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IISqEzP7a2XJ",
        "outputId": "2c6f55c7-412f-42a6-c1e7-cdf0c432070b"
      },
      "outputs": [],
      "source": [
        "print(\"Cosine similarity between 'alice' \" + \"and 'gloomily' - CBOW : \",\n",
        "      cbow_model.wv.similarity('alice', 'gloomily'))\n",
        "print(\"Cosine similarity between 'alice' \" + \"and 'gloomily' - SkipGram : \",\n",
        "      skipgram_model.wv.similarity('alice', 'gloomily'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuQVaf3khVwA",
        "outputId": "f168e854-ce1f-4580-f4dc-3b91d74edffc"
      },
      "outputs": [],
      "source": [
        "import gensim.downloader\n",
        "print(list(gensim.downloader.info()['models'].keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MtlKG4gh7Kq",
        "outputId": "4aa5425c-e97b-4233-f1e5-8f3d6e088b9a"
      },
      "outputs": [],
      "source": [
        "word2vec_precomputed_model = gensim.downloader.load('word2vec-google-news-300')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gedh6lYiiGZd",
        "outputId": "6810c28e-d700-42c2-84af-1edd7e423319"
      },
      "outputs": [],
      "source": [
        "word2vec_precomputed_model.most_similar('sport')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEp8gSlIDgsu",
        "outputId": "80aead13-3bf5-4de3-fc73-94f5df57441f"
      },
      "outputs": [],
      "source": [
        "#get the most similar vector to \"alice\"\n",
        "cbow_model.wv.most_similar('alice', topn=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z85wr3l4QQ-0"
      },
      "source": [
        "Now let's see how to handle phrases on word2vec. This is not the suggested solution, as \"full-phrase\" models like doc2vec have been shown to outperform word2vec.\n",
        "We can handle handle phrases as list of word2vec vectors, and perform some mathematical operations on them (i.e., sum, average, subtract)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "YCwF0PO1QVjB"
      },
      "outputs": [],
      "source": [
        "query_phrase = \"sport in italy\"\n",
        "#sum the vectors of the individual words\n",
        "query_vector_sum = np.zeros(300)\n",
        "for word in query_phrase.split():\n",
        "  query_vector_sum += word2vec_precomputed_model.get_vector(word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFlBusPSfIUV",
        "outputId": "3c84c20e-31cc-45c7-b20b-3c36ce898900"
      },
      "outputs": [],
      "source": [
        "print(\"Cosine similarity with 'football' - Google News (SUM) : \",\n",
        "      cosine_similarity([query_vector_sum], [word2vec_precomputed_model.get_vector(\"football\")])[0][0])\n",
        "print(\"Cosine similarity with 'hockey' - Google News (SUM) : \",\n",
        "      cosine_similarity([query_vector_sum], [word2vec_precomputed_model.get_vector('hockey')])[0][0])\n",
        "print(\"Cosine similarity with 'politics' - Google News (SUM) : \",\n",
        "      cosine_similarity([query_vector_sum], [word2vec_precomputed_model.get_vector('politics')])[0][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLC0NJLmtsor"
      },
      "source": [
        "## Other types of embeddings (Entity and Graph embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSEKtMwXhDiG"
      },
      "source": [
        "And we can also apply this concept to entity embeddings, using Wikipedia as a backend"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPeBNWkrhJy2",
        "outputId": "04622766-3808-4fc8-d506-2f5319278c60"
      },
      "outputs": [],
      "source": [
        "!pip install wikipedia2vec\n",
        "!wget https://raw.githubusercontent.com/LorenzoBellomo/InformationRetrieval/refs/heads/main/data/enwiki_20180420_100d_part.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QlTf29tJiDg_"
      },
      "outputs": [],
      "source": [
        "from wikipedia2vec import Wikipedia2Vec\n",
        "wiki2vec = Wikipedia2Vec.load_text(\"enwiki_20180420_100d_part.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFQ_SMhmqpdz",
        "outputId": "cd413f3f-a311-4ac4-a82c-2e7bfdc3e373"
      },
      "outputs": [],
      "source": [
        "wiki2vec.most_similar(wiki2vec.get_word('the'), 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1zigxzpqwdr",
        "outputId": "962a115e-0410-4bb3-8b3e-e75c5d2b03af"
      },
      "outputs": [],
      "source": [
        "wiki2vec.most_similar(wiki2vec.get_word('biology'), 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfaDGd48rcRk"
      },
      "source": [
        "And also Embeddings for Graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "embzdivWrfM6",
        "outputId": "99e007e5-f3da-4531-a54a-6db10fe9b44d"
      },
      "outputs": [],
      "source": [
        "!pip install networkx node2vec\n",
        "import networkx as nx\n",
        "from node2vec import Node2Vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oRj6w6yscSU"
      },
      "source": [
        "Random walks with a length of 30 and a total number of walks equal to 200."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "5d4e1f4d8cf145b78207ac18fca6571c",
            "890454acebac42e2876aef3ec19636e0",
            "ade3792f254449e98b94e4fbad2381cd",
            "7a80c67ff91940998c1132e0e07e2935",
            "eceb97b767214341bdb35517dfe9d8f4",
            "de8778b02259491a9841c366b6c6b8af",
            "a592ac1b7145463bb535fb0f2f446606",
            "75d6fd27028b44fea502ded0a3584825",
            "127fea545196431a98e47e6876c59b66",
            "173edeb0912448cca55e7f2aefd98c74",
            "d44e06b6b4004fe99fa51db455b4709a"
          ]
        },
        "id": "m4b2QjAirozr",
        "outputId": "95f28ec5-51f6-4885-f006-59c9318aef8b"
      },
      "outputs": [],
      "source": [
        "G = nx.fast_gnp_random_graph(n=100, p=0.5)\n",
        "node2vec = Node2Vec(G, dimensions=64, walk_length=30, num_walks=200, workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WyL5b0vTsW5h"
      },
      "outputs": [],
      "source": [
        "model = node2vec.fit(window=10, min_count=1, batch_words=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUFG0AzZsndl"
      },
      "outputs": [],
      "source": [
        "model.wv.save_word2vec_format(\"embeddings_node2vec.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBOFX7gSsopE"
      },
      "outputs": [],
      "source": [
        "embeddings = {str(node): model.wv[str(node)] for node in G.nodes()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16SXDiI9ssDU",
        "outputId": "12b77ba8-1f67-4330-e483-60ba880a6195"
      },
      "outputs": [],
      "source": [
        "embeddings[\"0\"]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "127fea545196431a98e47e6876c59b66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "173edeb0912448cca55e7f2aefd98c74": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d4e1f4d8cf145b78207ac18fca6571c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_890454acebac42e2876aef3ec19636e0",
              "IPY_MODEL_ade3792f254449e98b94e4fbad2381cd",
              "IPY_MODEL_7a80c67ff91940998c1132e0e07e2935"
            ],
            "layout": "IPY_MODEL_eceb97b767214341bdb35517dfe9d8f4"
          }
        },
        "75d6fd27028b44fea502ded0a3584825": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a80c67ff91940998c1132e0e07e2935": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_173edeb0912448cca55e7f2aefd98c74",
            "placeholder": "​",
            "style": "IPY_MODEL_d44e06b6b4004fe99fa51db455b4709a",
            "value": " 100/100 [00:00&lt;00:00, 129.94it/s]"
          }
        },
        "890454acebac42e2876aef3ec19636e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de8778b02259491a9841c366b6c6b8af",
            "placeholder": "​",
            "style": "IPY_MODEL_a592ac1b7145463bb535fb0f2f446606",
            "value": "Computing transition probabilities: 100%"
          }
        },
        "a592ac1b7145463bb535fb0f2f446606": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ade3792f254449e98b94e4fbad2381cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75d6fd27028b44fea502ded0a3584825",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_127fea545196431a98e47e6876c59b66",
            "value": 100
          }
        },
        "d44e06b6b4004fe99fa51db455b4709a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de8778b02259491a9841c366b6c6b8af": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eceb97b767214341bdb35517dfe9d8f4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
